{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 145 sources from C:\\splat-master/resources/Data/Public/LRIS-RED/ to spectral database\n"
     ]
    }
   ],
   "source": [
    "from astropy import units as u\n",
    "from astropy import coordinates as coord\n",
    "from astropy import coordinates as coord\n",
    "from astropy import units as u\n",
    "from astropy.table import Table\n",
    "from time import process_time\n",
    "\n",
    "import astroquery\n",
    "from astroquery.simbad import Simbad\n",
    "from astroquery.vo_conesearch import conf, conesearch, vos_catalog\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import splat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customize SIMBAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_simbad(path):\n",
    "    \"\"\"\n",
    "    my_simbad(path)\n",
    "    \n",
    "    Create an customized SIMBAD instance with specified VO table fields. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: string\n",
    "        A string, specifies the path to the excel file that stores the names of the VO table fields.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    out:\n",
    "        An customized astroquery.simbad.Simbad() instance.\n",
    "    \n",
    "    \n",
    "    Comments:    \n",
    "    -------\n",
    "    You can customize the VO Table through modifying \"Catalogs and columns.xlsx\". Or, simply modifying the returned incident.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    fields_to_add = pd.read_excel(path) # read in the fields we want from the excel sheet\n",
    "    fields_to_add = fields_to_add.where(fields_to_add['output name'] != '[drop]').dropna(how='all') # drop the unwanted fields\n",
    "\n",
    "    fields_to_add['input name'] = fields_to_add['input name'].apply(lambda x: x[:-2] + '(' + x[-1] + ')' if 'FLUX' in x else x) # reformat from \"FLUX_U\" to \"FLUX(U)\"\n",
    "    fields_to_add['input name'] = fields_to_add['input name'].apply(lambda x: x.split('(')[0].lower() + '(' + x.split('(')[1]  if '(' in x else x) # reformat from \"FLUX(U)\" to \"flux(U)\" This way we preserve the captial and lower cases inside the parentheses\n",
    "    fields_to_add['input name'] = fields_to_add['input name'].apply(lambda x: x if '(' in x else x.lower()) # reformat: convert all others to lower cases.\n",
    "\n",
    "    fields_to_add['input name'] = fields_to_add['input name'].replace({'plx_value':'plx', 'mk_spectral_type':'mk', 'sp_type':'sptype'}) # reformat some other fields\n",
    "\n",
    "    fields_to_add.drop(index=0, axis=1, inplace=True) # drop the row 'main_id' to avoid repeated fields. 'main_id' is already included as default.\n",
    "\n",
    "    fields_to_add.reset_index(inplace=True) # reset index which was messed up when we drop the unwanted fields.\n",
    "    fields_to_add.drop(columns='index', axis=0, inplace=True)\n",
    "\n",
    "    fields_list = list(fields_to_add['input name']) # create a list to add to the search fields\n",
    "    fields_list.append('otype')\n",
    "    \n",
    "    customSimbad = Simbad()\n",
    "    \n",
    "    for item in fields_list:\n",
    "        try:\n",
    "            customSimbad.add_votable_fields(item)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    print('\"customSimbad\" is ready')\n",
    "    return customSimbad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"customSimbad\" is ready\n"
     ]
    }
   ],
   "source": [
    "customSimbad = my_simbad('./Catalogs and columns.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_otypes = ['X','QSO', 'Galaxy', 'Blue', 'Radio', 'WD*', 'SN', 'Candidate_RGB*', 'Planet', 'Planet?', 'GroupG', 'Unknown', 'RadioG', 'GinCl','BClG', 'Compact_Gr_G','ClG', 'LINER', 'Seyfert_1','AGN', 'EmG', 'GinGroup', 'V*', \n",
    "                   'Inexistent', 'Radio(mm)', 'S*', 'HB*', 'Seyfert_2', 'MolCld', 'DkNeb', 'gammaBurst', 'RGB*', 'UV', 'C*', 'YSO', 'GiC','IR>30um']\n",
    "\n",
    "unwanted_spt = ['IV', 'III', 'II', 'G', 'F', 'A', 'B', 'O']\n",
    "\n",
    "favorite_otypes = ['low-mass*', 'BYDra', 'brownD*', 'PM*', 'BY*', 'Fl*', 'Flare*', 'SB*', 'Ro*','LM*', 'RotV*','Candidate_brownD*','Candidate_Hsd','Er*']\n",
    "\n",
    "bibcode_list = ['2013AJ....145..102L', '2007ApJ...669.1235L', '2020AJ....159...30H']\n",
    "\n",
    "def o_filter(df,extra=[],olist=unwanted_otypes):\n",
    "    \"\"\"\n",
    "    o_filter(df,extra=[],olist=unwanted_otypes)\n",
    "    \n",
    "    Filtering out entries with unwanted object types from the search result\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df:\n",
    "        A Pandas.DataFrame object that stores the search result from Simbad().query_region.\n",
    "    \n",
    "    extra:\n",
    "        Append object types to be filtered.\n",
    "    \n",
    "    olist:\n",
    "        A list that stores the unwanted object types in string form. Default set to \"unwanted_otypes\"\n",
    "    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    out:\n",
    "        A Pandas.DataFrame that excludes the specified object types.\n",
    "    \"\"\"    \n",
    "    if len(extra) ==0:\n",
    "        result = df.drop(index = df[df['OTYPE'].str.decode('ascii').isin(olist)].index)\n",
    "        return result\n",
    "    else:\n",
    "        olist.extend(extra)\n",
    "        result = df.drop(index = df[df['OTYPE'].str.decode('ascii').isin(olist)].index)\n",
    "        return result\n",
    "\n",
    "def s_filter(df):\n",
    "    \"\"\"\n",
    "    s_filter(df)\n",
    "    \n",
    "    Filter out unwanted spectral types from the search result.\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df:\n",
    "        A Pandas.DataFrame that stores the search result from Simbad().query_region.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    out:\n",
    "        A Pandas.DataFrame that excludes the spcified spectral types.\n",
    "    \n",
    "    Notes:\n",
    "    -------\n",
    "        The unwanted spectral types are predefined by \"unwanted_spt\".\n",
    "    \"\"\"    \n",
    "    result = df.drop(index = df[df['SP_TYPE'].str.decode('ascii').apply(lambda x: 'y' if any(ele in x for ele in unwanted_spt) else '') == 'y'].index)\n",
    "    return result\n",
    "\n",
    "def take_favorite(df):\n",
    "    \"\"\"\n",
    "    take_favorite(df)\n",
    "    \n",
    "    Take search result with specified object types listed in \"favorite_otypes\" and exclude the others.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df:\n",
    "        A Pandas.DataFrame object that stores the search result from Simbad().query_region.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    out:\n",
    "        A Pandas.DataFrame that includes only the specified object types.\n",
    "    \n",
    "    Notes:\n",
    "    -------\n",
    "        The favorite object types are predefined by \"favorite_otypes\".\n",
    "    \"\"\"        \n",
    "    if any(ele in list(df['OTYPE'].str.decode('ascii').unique()) for ele in favorite_otypes):\n",
    "        result = df[df['OTYPE'].str.decode('ascii').isin(favorite_otypes)]\n",
    "    else:\n",
    "        result = df\n",
    "    return result\n",
    "\n",
    "def magnet_V(df):\n",
    "    \"\"\"\n",
    "    magnet_V(df)\n",
    "    \n",
    "    Take search result with spectral type suffix \"V\" and exclude the others.\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df:\n",
    "        A Pandas.DataFrame object that stores the search result from Simbad().query_region.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    out:\n",
    "        A Pandas.DataFrame object.\n",
    "    \n",
    "    Notes:\n",
    "    -------\n",
    "        If none of the search results satisfies the requirement then the original results are returned.\n",
    "    \"\"\"        \n",
    "    if any(('V' or 'M') in x for x in df['SP_TYPE'].str.decode('ascii')):\n",
    "        df = df[[('V' or 'M') in x for x in df['SP_TYPE'].str.decode('ascii')]]\n",
    "        return df\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def compare_spt(df, index, diff=3):\n",
    "    \"\"\"\n",
    "    magnet_V(df)\n",
    "    \n",
    "    Compare spectral types between ours and the one in SIMBAD. If smaller than indicated then we pick the source.\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df:\n",
    "        A Pandas.DataFrame object that stores the search result from Simbad().query_region.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    out:\n",
    "        A Pandas.DataFrame object.\n",
    "    \n",
    "    Notes:\n",
    "    -------\n",
    "        If none of the search results satisfies the requirement then the original results are returned.\n",
    "    \"\"\"   \n",
    "    temp = df[df['SP_TYPE'].str.decode('ascii').apply(lambda x: abs(splat.typeToNum(x) - splat.typeToNum(kast['LSPN_SPT'][index]))) <= diff].copy()\n",
    "    if len(temp) == 0:\n",
    "        return df\n",
    "    else:\n",
    "        return temp\n",
    "\n",
    "def filter_z(df):\n",
    "    result = magnet_V(take_favorite(s_filter(o_filter(temp,['**']))))\n",
    "    return result\n",
    "\n",
    "def go_query(length=25):\n",
    "    t1 = process_time()\n",
    "    raw_result = customSimbad.query_region(kast['SKYCOORD'][0], radius = 2*u.arcmin).to_pandas()\n",
    "    for i in range(1, length):\n",
    "        try:\n",
    "            temp = customSimbad.query_region(kast['SKYCOORD'][i], radius = 2*u.arcmin).to_pandas()\n",
    "            temp = s_filter(o_filter(temp))\n",
    "            temp = compare_spt(temp,i)\n",
    "            temp = take_favorite(temp)\n",
    "            temp = magnet_V(temp)\n",
    "            raw_result = raw_result.append(temp.iloc[0])\n",
    "        except:\n",
    "            raw_result = raw_result.append(pd.Series(dtype='str'), ignore_index=True)\n",
    "    t2 = process_time()\n",
    "    raw_result.reset_index(inplace=True)\n",
    "    raw_result.drop('index', axis=1, inplace=True)\n",
    "    # For some reason SIMBAD returns some columns twice. Below I manually dropped those.\n",
    "    raw_result = raw_result.drop(columns=['RA_PREC', 'DEC_PREC', 'COO_ERR_MAJA',\n",
    "       'COO_ERR_MINA', 'COO_ERR_ANGLE', 'COO_QUAL', 'COO_WAVELENGTH','MK_ds', 'MK_mss','SP_QUAL','RA_2','DEC_2','COO_BIBCODE_2','SP_BIBCODE_2'], axis=0)\n",
    "    raw_result['FLAG'] = ''\n",
    "    print(str((t2-t1)/60) + ' mins')\n",
    "    return raw_result\n",
    "\n",
    "def single_query(x, r=2, extra_filter=[], extra_fav=[], verbose=False):\n",
    "    x = splat.properCoordinates(x)\n",
    "    try:\n",
    "        temp = customSimbad.query_region(x, radius = r*u.arcmin).to_pandas()\n",
    "        temp = take_favorite(s_filter(o_filter(temp, extra_filter)))\n",
    "        temp = magnet_V(temp)\n",
    "        raw_result = temp\n",
    "    except:\n",
    "        if verbose==True:\n",
    "            print('no result found')\n",
    "    \n",
    "    raw_result.reset_index(inplace=True)\n",
    "    raw_result.drop('index', axis=1, inplace=True)\n",
    "    # For some reason SIMBAD returns some columns twice. Below I manually dropped those.\n",
    "    raw_result = raw_result.drop(columns=['RA_PREC', 'DEC_PREC', 'COO_ERR_MAJA',\n",
    "       'COO_ERR_MINA', 'COO_ERR_ANGLE', 'COO_QUAL', 'COO_WAVELENGTH','MK_ds', 'MK_mss','SP_QUAL','RA_2','DEC_2','COO_BIBCODE_2','SP_BIBCODE_2'], axis=0)\n",
    "    return raw_result\n",
    "\n",
    "def go_querybib(bibs):\n",
    "    temp = []\n",
    "    for i in bibs:\n",
    "        temp.append(Simbad.query_bibobj(i).to_pandas())\n",
    "    result = pd.concat(temp, ignore_index=True)\n",
    "    return result\n",
    "\n",
    "def decode(item):\n",
    "    try:\n",
    "        return item.decode('ascii')\n",
    "    except:\n",
    "        return item\n",
    "    \n",
    "def diff_spt(df, verbose=False):\n",
    "    df['diff_mk'] = abs(raw['MK_Spectral_type'].str.decode('ascii').apply(lambda x: splat.typeToNum(x)) - kast['LSPN_SPT'].apply(lambda x: splat.typeToNum(x)))\n",
    "    df['diff_simbad'] = abs(raw['SP_TYPE'].str.decode('ascii').apply(lambda x: splat.typeToNum(x)) - kast['LSPN_SPT'].apply(lambda x: splat.typeToNum(x)))\n",
    "    df['DIFF_SPT'] = df[['diff_mk','diff_simbad']].min(axis=1)\n",
    "    if verbose:\n",
    "        return df\n",
    "    else:\n",
    "        df.drop(columns=['diff_mk','diff_simbad'], axis=0, inplace=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-6e7f56e66435>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcolumns_to_convert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'b'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mcolumns_to_convert\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'raw' is not defined"
     ]
    }
   ],
   "source": [
    "def rename_columns:\n",
    "    columns_to_convert = []\n",
    "    for i in raw.columns:\n",
    "        if 'b' in str(raw.loc[0, i]):\n",
    "            columns_to_convert.append(i)\n",
    "        \n",
    "    for i in columns_to_convert:\n",
    "        raw[i] = raw[i].str.decode('ascii')\n",
    "\n",
    "    ionames = pd.read_excel('./Catalogs and columns.xlsx')\n",
    "    ionames = ionames[ionames['output name'] != '[drop]'].dropna(how='all') # obtain the input name vs output name\n",
    "    new_names = ionames[['input name','output name']].set_index('input name')['output name'].to_dict() # turn the input vs output name into a dictionary for the next step\n",
    "    raw.rename(columns=new_names, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
