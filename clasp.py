"""###################### Insert your own paths here ######################import syspaths = []for path in paths:    if path not in sys.path:        sys.path.append(path)#print(sys.path)"""# Import libraries# main splat importimport splat as spimport splat.plot as splotimport splat.photometry as sphotimport splat.empirical as spemimport splat.model# other useful importsimport matplotlib.pyplot as pltimport numpy as npimport pandas as pdimport astropy.units as ufrom astropy.io import fitsfrom astropy.utils.data import download_fileimport statisticsfrom givePercentage import *## Classify class that contains methods to simplify the process of reducing dataclass Classify:    def __init__(self, path, file, file_type='fits', name=''):        '''        :Purpose:            To create an instance variable within the class Classify with the            required parameters to successfully  utilize the splat method used            the methods contained within        :Required Parameters:            :param path: The path to the folder that contains the file(s)                being analyzed            :param file: The name of the file being analyzed        :Optional Parameters:            :param file_type: The type of file that is being analyzed            :param name: The name of the object observed within the file used            to facilitate plotting and referencing        :Output:            N/a, constructor        :Example:            file = Classify(path='/home/Desktop/',                            file='spex_prism_0412+1044_160930.fits',                            name='0412+1044')        '''        path = path        filename = path + file        self.file = filename        self.file_type = file_type        self.name = name    def classifyByStandard(self, plot=False, file=False, average=False):        '''        :Purpose:            Determine the spectral type and uncertainty for a spectrum by            direct comparison to defined spectral standards. Dwarf standards            span M0-T9 and include the standards listed in            `Burgasser et al. (2006)            <http://adsabs.harvard.edu/abs/2006ApJ...637.1067B>`_,            `Kirkpatrick et al. (2010)            <http://adsabs.harvard.edu/abs/2010ApJS..190..100K>`_ and            `Cushing et al. (2011)            <http://adsabs.harvard.edu/abs/2011ApJ...743...50C>`_.            Comparison to subdwarf and extreme subdwarf standards may also be            done. Returns the best match or an F-test weighted mean and            uncertainty. There is an option to follow the procedure of            `Kirkpatrick et al. (2010)            <http://adsabs.harvard.edu/abs/2010ApJS..190..100K>`_,            fitting only in the 0.9-1.4 micron region.        :Required Parameters:            N/a, No parameters are required but the calling object must be an            instance variable of the class Classify        :Optional Parameters:            N/a, No parameters are required but the calling object must be an            instance variable of the class Classify        :Output:             A tuple listing the best match standard and uncertainty based on             F-test weighting and systematic uncertainty of 0.5 subtypes        :Example:            import splat            file = Classify('/home/Desktop/',                            'spex_prism_0412+1044_160930.fits',                            name='0412+1044')            starType = file.classifyByStandard()        '''        sp1 = splat.Spectrum(file=self.file, file_type=self.file_type,                             name=self.name)        result = splat.classifyByStandard(sp1, plot=plot, file=file,                                          average=average)        return result    def classifyByIndex(self, ref="burgasser"):        '''        :Purpose:            Determine the spectral type and uncertainty for a spectrum based            on indices. Makes use of published index-SpT relations from            `Reid et al. (2001)            <http://adsabs.harvard.edu/abs/2001AJ....121.1710R>`_;            `Testi et al. (2001)            <http://adsabs.harvard.edu/abs/2001ApJ...552L.147T>`_;            `Allers et al. (2007)            <http://adsabs.harvard.edu/abs/2007ApJ...657..511A>`_; and            `Burgasser (2007)            <http://adsabs.harvard.edu/abs/2007ApJ...659..655B>`_.            Returns 2-element tuple containing spectral type            (numeric or string) and uncertainty.        :Required Parameters:            N/a, No parameters are required but the calling object must be an            instance variable of the class Classify        :Optional Parameters:            N/a, No parameters are required but the calling object must be an            instance variable of the class Classify        :Output:            The index of the star        :Example:            import splat            file = Classify('/home/Desktop/',                            'spex_prism_0412+1044_160930.fits',                            name='0412+1044')            starType = file.classifyByIndex()        '''        sp1 = splat.Spectrum(file=self.file, file_type=self.file_type,                             name=self.name)        result = splat.classifyByIndex(sp1, ref=ref)        return result    def classifyGravity(self):        '''        :Purpose:            Determine the gravity classification of a brown dwarf using the            method of `Allers & Liu (2013)            <http://adsabs.harvard.edu/abs/2013ApJ...772...79A>`_.        :Parameters:            N/a, No parameters are required but the calling object must be an            instance variable of the class Classify        :Output:            Either a string specifying the gravity classification or a            dictionary specifying the gravity scores for each index        :Example:            >>> import splat            >>> file = Classify('/home/Desktop/',                                'spex_prism_0412+1044_160930.fits',                                name='0412+1044')            >>> starType = file.classifyGravity()        '''        sp1 = splat.Spectrum(file=self.file, file_type=self.file_type,                             name=self.name)        try:            result = splat.classifyGravity(sp1)            return result        except:            return np.nan    def measureIndex(self, num_init, num_fin, den_init, den_fin):        '''        :Purpose:            Measure an index on a spectrum based on defined methodology            measure method can be mean, median, integrate            index method can be ratio = 1/2, valley = 1-2/3, OTHERS        :Required Parameters:            :param num_init: The initial value for the range in the numerator            :param num_fin: The final value for the range in the numerator            :param den_init: The initial value for the range in the denominator            :param den_fin: The final value for the range in the denominator        :Output:            Index value and uncertainty        :Example:            >>> import splat            >>> file = Classify('/home/Desktop/',                                'spex_prism_0412+1044_160930.fits',                                name='0412+1044')            >>> starType = file.measureIndex(1.1, 1.2, 1.22, 1.32)        '''        sp1 = splat.Spectrum(file=self.file, file_type=self.file_type,                             name=self.name)        result = splat.measureIndex(sp1, [[num_init, num_fin],[den_init, den_fin]])        return result    def measureIndexSet(self, ref='burgasser'):        '''        :Purpose:            Measures indices of ``sp`` from specified sets.        :Required Input:            :param ref='burgasser': string identifying the index set                you want to measure, as contained in the variable                splat.INDEX_SETS        :Output:            A dictionary containing the names of each index pointed            to tuple of (measurement,uncertainty)        :Example:            import splat            file = Classify('/home/Desktop/',                            'spex_prism_0412+1044_160930.fits',                            name='0412+1044')            file.measureIndexSet(ref='burgasser')        '''        sp1 = splat.Spectrum(file=self.file, file_type=self.file_type,                             name=self.name)        result = splat.measureIndexSet(sp1, ref=ref)        return result    def compareSpectrum(self, statistic):        '''        :Purpose:            Compare two spectra against each other within the same category of            star with the statistic='chisqr', 'stddev', or 'absdev'        :Input:            :param statistic: Possible inputs are 'chisqr', 'stddev', and '                absdev'        :Output:            The value of the desired statistic as well as the optimal scale            factor.        :Example:            import splat            file = Classify('/home/Desktop/',                            'spex_prism_0412+1044_160930.fits',                            name='0412+1044')            starType = file.compareSpectrum('chisqr')        '''        sp1 = splat.Spectrum(file=self.file, file_type=self.file_type,                             name=self.name)        result = splat.classifyByStandard(sp1)        sp2 = splat.getSpectrum(spt=result[0], lucky=True)[0]        sp1.normalize()        sp2.normalize()        stat = splat.compareSpectra(sp1, sp2, statistic=statistic)        return stat        """    def compareSpectrum_stddev(self):        '''        :Purpose:            Compare two spectra against each other within the same category of            star with the statistic='stddev'        :Output:            The value of the desired statistic as well as the optimal scale            factor.        :Example:            import splat            file = Classify('/home/Desktop/',                            'spex_prism_0412+1044_160930.fits',                            name='0412+1044')            starType = file.compareSpectrum_stddev()        '''        sp1 = splat.Spectrum(file=self.file, file_type=self.file_type,                             name=self.name)        result = splat.classifyByStandard(sp1)        sp2 = splat.getSpectrum(spt=result[0], lucky=True)[0]        sp1.normalize()        sp2.normalize()        stddev = splat.compareSpectra(sp1, sp2, statistic='stddev')        return stddev    def compareSpectrum_absdev(self):        '''        :Purpose:            Compare two spectra against each other within the same category of            star with the statistic='absdev'        :Output:            The value of the desired statistic as well as the optimal scale            factor.        :Example:            import splat            file = Classify('/home/Desktop/',                            'spex_prism_0412+1044_160930.fits',                            name='0412+1044')            starType = file.compareSpectrum_absdev()        '''        sp1 = splat.Spectrum(file=self.file, file_type=self.file_type,                             name=self.name)        result = splat.classifyByStandard(sp1)        sp2 = splat.getSpectrum(spt=result[0], lucky=True)[0]        sp1.normalize()        sp2.normalize()        absdev = splat.compareSpectra(sp1, sp2, statistic='absdev')        return absdev        """    def typeToNum(self, value):        """        :Purpose:            Converts between string and numeric spectral types, with the option            of specifying the class prefix/suffix and uncertainty tags        :Required Input:            No input required but the value must first be converted to type            with classifyByStandard or classifyByIndex and select the 0th value        :Outputs:            The number or string of a spectral type        :Example:            import splat            file = Classify('/home/Desktop/',                            'spex_prism_0412+1044_160930.fits',                            name='0412+1044')[0]            r = file.classifyByStandard()            file.typeToNum(r[0])        """        num = splat.typeToNum(str(value))        return num    def modelFitGrid(self, model, teff_range=[400,4000], plot=False,                     file="fit1507", calName='2MASS J', calNum=12.32,                     absolute=True, verbose=False):        """        :Purpose:            Fits a spectrum to a grid of atmosphere models, reports            the best-fit and weighted average parameters, and returns            either a dictionary with the best-fit model parameters or            the model itself scaled to the optimal scaling factor. If            spectrum is absolutely flux calibrated with the            `fluxcalibrate()`_ method, the routine will also calculate            the equivalent radii of the source. In addition, an input            radius can be used to provide an additional constraint on            the model        :Required Parameters:            :param teff_range: set to the range of temperatures over which                model fitting will be done            :param model: The model by which the spectrum will be                compared to        :List of Models:            ["btcond",            "btnextgen",            "btsettl08",            "btsettl15",            "burrows06",            "cond01",            "drift",            "dusty01",            "madhusudhan11",            "morley12",            "morley14",            "saumon12",            "sonora18",            "veyette"]        :Output:            Output is a dictionary containing the best-fit model            parameters: model name, teff, logg, z, fsed, kzz, cloud            and slit, as well as the scaling factor for the model and            comparison statistic.        :Example:            >>> import splat            >>> from clasp import *            >>> file = Classify('/home/Desktop/',                                'spex_prism_0412+1044_160930.fits',                                name='0412+1044')            >>> file.modelFitGrid(model="Saumon08")        """        sp1 = splat.Spectrum(file=self.file, file_type=self.file_type,                             name=self.name)        sp1.fluxCalibrate(calName, calNum, absolute=absolute)        result = splat.model.modelFitGrid(sp1, plot=plot, file=file,                                          teff_range=teff_range, modelset=model,                                          verbose=verbose)        return result    def typeToTeff(self, uncertainty=[0.0], reference='stephens09',                   nsamples=100, reverse=False, string=False, verbose=False):        """        :Purpose:            Returns an effective temperature (Teff) and its uncertainty            for a given spectral type (or vice versa) based on an            empirical relation        :Required Inputs:            A single or array of either spectral types or effective            temperatures (reverse). If spectral types, these can be            ints, floats or strings from 0 (K0) and 49.0 (Y9).If            temperatures, these can be ints or floats and assumed to            be in units of Kelvin.            Note: you must set reverse=True to convert temperature to            spectral type.        :Optional Inputs:            :param uncertainty: uncertainty of spectral type/temperature                (default = 0.001; also 'unc', 'spt_e')            :param reference: Teff/SpT relation used to compute the effective                temperature (also 'set'). Options are:            - *stephens* (default): Teff/SpT relation from `Stephens et al.                (2009) <http://adsabs.harvard.edu/abs/2009ApJ...702..154S>`_.                Allowed spectral type range is M6 to T8 and uses alternate                coefficients for L3 to T8.            - *golimowski*: Teff/SpT relation from `Golimowski et al. (2004)                <http://adsabs.harvard.edu/abs/2004AJ....127.3516G>`_.                Allowed spectral type range is M6 to T8.            - *looper*: Teff/SpT relation from `Looper et al. (2008)                <http://adsabs.harvard.edu/abs/2008ApJ...685.1183L>`_.                Allowed spectral type range is L0 to T8.            - *marocco*: Teff/SpT relation from `Marocco et al. (2013)                <http://adsabs.harvard.edu/abs/2013AJ....146..161M>`_.                Allowed spectral type range is M7 to T8.            - *filippazzo*: Teff/SpT relation from Filippazzo et al. (2015)                <http://adsabs.harvard.edu/abs/2015ApJ...810..158F>`_.                Allowed spectral type range is M6 to T9.            - *faherty*: Teff/SpT relation from Faherty et al. (2016)                <http://adsabs.harvard.edu/abs/2016ApJS..225...10F>`_.                This relation is defined for normal dwarfs (M7 < SpT < T8),                young dwarfs (``-young`` and ``-young2``, M7 < SpT < L7),                and young dwarfs in groups (``-group``, M7 < SpT < L7)            - *dupuy*: Teff/SpT relation from Dupuy et al. (2017).                This relation is defined for Saumon & Marley (2008) models                (``-saumon``, L1.5 < SpT < T5) and Lyon models                (``-lyon``, M7 < SpT < T5)            :param reverse: set to True to convert effective temperature to spectral type (default=False)            :param nsamples: number of samples to use in Monte Carlo error estimation (default=100)        :Output:            A 2-element tuple containing the Teff/SpT and its uncertainty        """        m0 = splat.typeToNum('M0')        m6 = splat.typeToNum('M6')        t8 = splat.typeToNum('T8')        spt = self.classifyByStandard()        num = self.typeToNum(spt[0])        if m6 <= num and t8 > num:            teff = splat.empirical.typeToTeff(var=num, uncertainty=uncertainty,                                              reference='stephens',                                              nsamples=nsamples,                                              reverse=reverse, string=string,                                              verbose=verbose)[0]            teff = str(teff)[:-1]            teff = float(teff)            return teff        if m0 <= num and m6 > num:            teff = splat.empirical.typeToTeff(var=num, uncertainty=uncertainty,                                              reference='pecaut',                                              nsamples=nsamples,                                              reverse=reverse, string=string,                                              verbose=verbose)[0]            teff = str(teff)[:-1]            teff = float(teff)            return teffclass Source:    #initial function will take the information required to get the coordinates from the fits file    # Credit: Christopher Danner    def __init__(self, path_name):        Header = fits.open(path_name)[0].header        for x in range(len(list(Header))):            if 'RA' == list(Header)[x] or '_RA' in list(Header)[x]:                RA_header = list(Header)[x]            if 'DEC' == list(Header)[x] or '_DEC' in list(Header)[x]:                DEC_header = list(Header)[x]        try:            self.RA = Header[RA_header]            self.DEC = Header[DEC_header]        except UnboundLocalError as error:            #This means that RA_header or DEC_header did not get a value bound to them.  Could either mean that the Header does            #not contain an RA or DEC value, or that the RA/DEC value is not recognized            print(list(Header))            print("The function could not find a RA or DEC label in the above Header.  Double check to make sure that the \ given file contains the coordinates")    def set_unit(self):        if ':' in self.RA:            self.RA = convert_coords(self.RA, self.DEC)[0]            self.DEC = convert_coords(self.RA, self.DEC)[1]            self.unit = 'degree'        else:            self.unit = 'degree'    def cat_num(self):        self.given_catalogs = []        for x in range(len(catalogs)):            if 'No data' in cat_results(self.RA, self.DEC, cat = catalogs[x],                                        unit = self.unit):                continue            else:                self.given_catalogs.append(catalogs[x])def indexDicToCSV(path='', csvName = '', ref='burgasser', fileNameList=[],                  index=False, header=True):    """    Parameters    ----------    pathName : TYPE, optional. Write the path to where the csv file will be    saved        DESCRIPTION. The default is ''.    ref : TYPE, optional        DESCRIPTION. The default is 'burgasser'.        Other options are: ['bardalez', 'burgasser', 'tokunaga', 'reid',                            'geballe', 'allers', 'testi', 'slesnick', 'mclean',                            'rojas']    fileNameList : TYPE, optional        DESCRIPTION. The default is []. Give a list of the names of the files        to be analyzed.    index : TYPE, optional        DESCRIPTION. The default is False. To put a index in the final csv file    header : TYPE, optional.        DESCRIPTION. The default is True. To put a header in the final csv file.    Returns    -------    None. A csv with the results is saved in the directory listed in :param:        pathName    Example    -------    >>> import splat    >>> from clasp import *    >>> fileNameList = ["spex_prism_0004-1336_160922.fits",                        "spex_prism_0004-2604_160803.fits"]    >>> indexDicToCSV(pathName="/Users/home/Desktop/", ref="allers",                      fileNameList=fileNameList)    """    indexSet = []    for i in fileNameList:        file = Classify(path=path, file=str(i))        inter = file.measureIndexSet(ref=ref)        indexSet.append(inter)    categories = ['FileName']    for key in indexSet[0].keys():        if key not in categories:            categories.append(key)            categories.append(key + ' err')    pathName = path + csvName    csvFileName = pathName + "ref='" + ref + "'.csv"    print(csvFileName)    dictionary={}    dictionary['FileName']=fileNameList    for item in categories:        if 'FileName' in item:            continue        elif 'err' in item:            dictionary[item]=[]        elif 'err' not in item:            dictionary[item]=[]    for dic in indexSet:        for item in categories:            if 'FileName' in item:                continue            elif 'err' in item:                dictionary[item].append(dic[item[:-4]][1])            elif 'err' not in item:                dictionary[item].append(dic[item][0])    df = pd.DataFrame(dictionary, columns=categories)    df.to_csv(csvFileName, index=index, header=header)    print(df)def compareStarType(pathToFile, file, pathToSave, file_type='fits', name='',                    plt_xLim=[0.8,2.4], plt_yLim=[0,1.2], verbose=False,                    plot=False):    pathToFile = str(pathToFile + file)    sp1 = splat.Spectrum(file=pathToFile, file_type=file_type, name=name)    result = splat.classifyByStandard(sp1)    sp2 = splat.getSpectrum(spt=result[0], lucky=True)[0]    sp1.normalize()    sp2.normalize()    splat.compareSpectra(sp1, sp2, verbose=verbose, plot=plot,                         file=str(pathToSave + file + '.png'))    '''    plt.plot(sp1.wave, sp1.flux, 'b-')    plt.plot(sp2.wave, sp2.flux, 'g-')    plt.legend([file, sp2.name])    plt.xlim(plt_xLim)    plt.ylim(plt_yLim)    plt.xlabel('Wavelength (micron)')    plt.ylabel('Normalized Flux Density')    plt.show()    plt.savefig(file + '.png', bbox_inches='tight')    '''    print("The star is an " + result[0] + " type star.")def compareStarIndex(file, file_type='fits', name='', plt_xLim=[0.8,2.4],                     plt_yLim=[0,1.2]):    sp1 = splat.Spectrum(file=file, file_type=file_type, name=name)    result = splat.classifyByIndex(sp1)    starType = result[0][:-2]    sp2 = splat.getSpectrum(spt=starType, lucky=True)[0]    sp1.normalize()    sp2.normalize()    plt.plot(sp1.wave, sp1.flux, 'b-')    plt.plot(sp2.wave, sp2.flux, 'g-')    plt.legend([sp1.name, sp2.name])    plt.xlim(plt_xLim)    plt.ylim(plt_yLim)    plt.xlabel('Wavelength (micron)')    plt.ylabel('Normalized Flux Density')    print("The star is an " + result[0] + " type star.")def dicToCSV(listOfDics, path='', fileTitle='', fileNameList=[], numOfModels=1,             index=False, header=True, fileName=True, err=False):    # Create categories list    if fileName==True:        categories = ['FileName']    if fileName==False:        categories=[]    # Create error columns is err==True    if err==True:        for key in listOfDics[0].keys():            if key not in categories:                categories.append(key)                categories.append(key + ' err')    if err==False:        for key in listOfDics[0].keys():            if key not in categories:                categories.append(key)    # Create empty dictionary    dictionary={}    # Check if fileNameList is empty, if so do not add 'FileName' column, else:    #do    if not fileNameList:        pass    else:        dictionary['FileName']=[]    for item in categories:        if 'FileName' in item:            continue        else:            dictionary[item]=[]    print(dictionary)    for fname in fileNameList:        for i in range(numOfModels):            dictionary['FileName'].append(fname)    for dic in listOfDics:        #print(dictionary)        for item in categories:            if 'FileName' in item:                continue            if item not in dic:                dictionary[item].append(np.nan)            elif 'err' in item:                dictionary[item].append(dic[item[:-4]][1])            elif 'err' not in item:                dictionary[item].append(dic[item])    print(dictionary)    csvFileName = str(path) + str(fileTitle)    df = pd.DataFrame(dictionary, columns=categories)    df.to_csv(csvFileName, index=index, header=header)    print(df)def makePlot(model, modelString, dictionary={}, voice=False):    if len(model) > 0:        typeToTeff_list = []        for model_key in model.keys():            typeToTeff_list.append(dictionary[model_key])        model = list(model.values())        difference = []        i = 0        while i < len(typeToTeff_list):            diff = typeToTeff_list[i] - model[i]            difference.append(diff)            i+=1        difference.sort()        fig = plt.figure()        ax1 = fig.add_axes([0.1, 0.65, 0.8, .4],                        xlim=(0, 5000), ylim=(0, 5000))        ax2 = fig.add_axes([0.1, 0.1, 0.8, .4],                        ylim=(0, 20))        x = np.linspace(0, 5000)        ax1.plot(typeToTeff_list, model, 'b.', label=modelString)        ax1.plot(x, x, 'r--', label='$y = x$')        ax1.set_xlabel('Teffs from typeToTeffs')        ax1.set_ylabel('Teffs from modelFitGrid')        ax1.legend()        ax2.hist(difference, bins= 20, label='Difference')        ax2.set_ylabel('Difference = Teff(SpT)-Teff(model)')        median = '{:.0f}'.format(statistics.median(difference))        stdev = '{:.0f}'.format(statistics.stdev(difference))        ratio = '{:.1f}'.format(len(model) / stdev)        #plt.text(median, 0.2, str(median))        plt.text(min(difference), 15, "Difference = Teff(SpT)-Teff(model)" +                 '\nstdev = ' + str(stdev) + ' K' + '\nmedian = ' + str(median)                 + ' K' + "\nNo. of values = " + str(len(model)) + "\nRatio = "                 + str(ratio), horizontalalignment='left',                 verticalalignment='center')        plt.savefig(modelString + '.png', bbox_inches='tight')        print()    if len(model) == 0:        print("No Data for " + modelString)        if voice == True:            import os            os.system("say 'No data for ' " + modelString)def spectrumToCSV(Files, path, saveTo, csvName='', classifyByIndex = True,                  average=True, standard=True, gravity=True, chisqr=False,                  stddev=False, absdev=False, csvIndex=False):    """    Parameters    ----------    Files : TYPE, required        DESCRIPTION. The default is []. Enter the list of file names to be        added to the csv.    path : TYPE, required        DESCRIPTION. The default is ''. Enter the path to the files being        analyzed.    csvName : TYPE, required        DESCRIPTION. The default is ''. Enter the name you wish the csv file to        be named.    classifyByIndex : TYPE, optional        DESCRIPTION. The default is True. This adds the values returned by        splat.classifyByIndex to the csv file with references = ["burgasser",                                                                 "allers",                                                                 "reid"]    average : TYPE, optional        DESCRIPTION. The default is True. By changing this to False the        classifyByStandard method returns the "Best Standard" where setting        this to True returns the "Mean Standard"    Standard : TYPE, optional        DESCRIPTION. The default is True.    Gravity : TYPE, optional        DESCRIPTION. The default is True.    chisqr : TYPE, optional        DESCRIPTION. The default is True.    stddev : TYPE, optional        DESCRIPTION. The default is False.    absdev : TYPE, optional        DESCRIPTION. The default is False.    csvIndex : TYPE, optional        DESCRIPTION. The defualt is False. Change to True if you wish to have        an index in the final csv file.    Returns    -------    CSV file containing the classificiation information of the spectra    """    dictionary = {}    dictionary["Files"] = Files    dictionary["Shortnames"] = []    dictionary["Dates"] = []    dictionary["RA"] = []    dictionary["DEC"] = []    if isinstance(Files, list) == False:        Files = [Files]    if standard == True:        dictionary["Standard"] = []        dictionary["Standard_error"] = []    if gravity == True:        dictionary["Gravity"] = []    if chisqr == True:        dictionary["chisqr"] = []        dictionary["chisqr_error"] = []    if stddev == True:        dictionary["stddev"] = []        dictionary["stddev_error"] = []    if absdev == True:        dictionary["absdev"] = []        dictionary["absdev_error"] = []    if classifyByIndex == True:            indexList = ["burgasser", "allers", "reid"]            dictionary["Index_burgasser"] = []            dictionary["Index_burgasser_err"] = []            dictionary["Index_allers"] = []            dictionary["Index_allers_err"] = []            dictionary["Index_reid"] = []            dictionary["Index_reid_err"] = []    for file in Files:        givePercentage(file, Files)        name = file[11:-12]        date = file[21:-5]        p = Classify(path=path, file=file, name=name)        s = Source(path_name=path+file)        dictionary["Shortnames"].append("J" + name)        dictionary["Dates"].append(date)        dictionary["RA"].append(s.RA)        dictionary["DEC"].append(s.DEC)        if standard == True:            try:                #standard = p.classifyByStandard()                dictionary["Standard"].append(p.classifyByStandard(average=average)[0])                dictionary["Standard_error"].append(p.classifyByStandard(average=average)[1])                directories = os.listdir(saveTo)                if "StandardPlots" not in directories:                    os.mkdir(saveTo + "StandardPlots")                p.classifyByStandard(file=saveTo + "StandardPlots/" + file[:-5] + "_classification.png", plot=True)            except:                dictionary["Standard"].append(np.nan)                dictionary["Standard_error"].append(np.nan)        if gravity == True:            try:                dictionary["Gravity"].append(p.classifyGravity())            except:                dictionary["Gravity"].append(np.nan)        if classifyByIndex == True:            try:                #burgasser = p.classifyByIndex(ref="burgasser")                dictionary["Index_burgasser"].append(p.classifyByIndex(ref="burgasser")[0])                dictionary["Index_burgasser_err"].append(p.classifyByIndex(ref="burgasser")[1])            except:                dictionary["Index_burgasser"].append(np.nan)                dictionary["Index_burgasser_err"].append(np.nan)            try:                #allers = p.classifyByIndex(ref="allers")                dictionary["Index_allers"].append(p.classifyByIndex(ref="allers")[0])                dictionary["Index_allers_err"].append(p.classifyByIndex(ref="allers")[1])            except:                dictionary["Index_allers"].append(np.nan)                dictionary["Index_allers_err"].append(np.nan)            try:                #reed = p.classifyByIndex(ref="reed")                dictionary["Index_reid"].append(p.classifyByIndex(ref="reid")[0])                dictionary["Index_reid_err"].append(p.classifyByIndex(ref="reid")[1])            except:                dictionary["Index_reid"].append(np.nan)                dictionary["Index_reid_err"].append(np.nan)        if chisqr == True:            try:                #chisqr = p.compareSpectrum("chisqr")                dictionary["chisqr"].append(p.compareSpectrum("chisqr")[0])                dictionary["chisqr_error"].append(p.compareSpectrum("chisqr")[1])            except:                dictionary["chisqr"].append(np.nan)                dictionary["chisqr_error"].append(np.nan)        if stddev == True:            try:                #stddev = p.compareSpectrum("stddev")                dictionary["stddev"].append(p.compareSpectrum("stddev")[0])                dictionary["stddev_error"].append(p.compareSpectrum("stddev")[1])            except:                dictionary["stddev"].append(np.nan)                dictionary["stddev_error"].append(np.nan)        if absdev == True:            try:                #absdev = p.compareSpectrum("absdev")                dictionary["absdev"].append(p.compareSpectrum("absdev")[0])                dictionary["absdev_error"].append(p.compareSpectrum("absdev")[1])            except:                dictionary["absdev"].append(np.nan)                dictionary["absdev_error"].append(np.nan)    #print(dictionary)    csvFileName = saveTo + csvName    df = pd.DataFrame(data = dictionary, columns = list(dictionary.keys()))    df.to_csv(csvFileName, index=csvIndex, header=True)    print(df)def indexToCSV(Files, path, saveTo, csvName='', indexSet = True, csvIndex=False):    """    Parameters    ----------    Files : TYPE, required.        DESCRIPTION. The default is null. Enter either a single file or a list        of files to be evaluated.    path : TYPE, required.        DESCRIPTION. The default is null. Enter the path to where the file        being analyzed is located on your local computer as a string.    saveTo : TYPE, required.        DESCRIPTION. The default is null. Enter the path to where you wish        the final csv file to be saved to. You can also enter the name of the        file at the end of the pathname or you can use csvName instead.    csvName : TYPE, optonal.        DESCRIPTION. The default is ''. This will be the name of the csv file.        You can also add this to the end of :saveTo: instead.    indexSet : TYPE, optional        DESCRIPTION. The default is True. This adds the values returned by        splat.measureIndexSet to the csv file with references = ["burgasser",                                                                 "allers",                                                                 "geballe",                                                                 "testi",                                                                 "reid"]    Returns    -------    A csv file containing the values returned by splat.classifyByIndex and    splat.measureIndexSet in the directory defined in :saveTo:    """    dictionary = {}    dictionary["Files"] = Files    dictionary["Shortnames"] = []    dictionary["Dates"] = []    dictionary["RA"] = []    dictionary["DEC"] = []    if isinstance(Files, list) == False:        Files = [Files]    for file in Files:        givePercentage(file, Files)        name = file[11:-12]        date = file[21:-5]        p = Classify(path=path, file=file, name=name)        s = Source(path_name=path+file)        dictionary["Shortnames"].append("J" + name)        dictionary["Dates"].append(date)        dictionary["RA"].append(s.RA)        dictionary["DEC"].append(s.DEC)        if indexSet == True:            indexSetList = ["burgasser", "allers", "geballe", "reid", "testi"]            for ref in indexSetList:                s = p.measureIndexSet(ref=ref)                keys = list(s.keys())                for key in keys:                    if str(key + "_" + ref) not in list(dictionary.keys()):                        dictionary[key + "_" + ref] = []                        dictionary[key + "_" + ref + "_error"] = []                    if key in list(s.keys()):                        dictionary[key + "_" + ref].append(s[key][0])                        dictionary[key + "_" + ref + "_error"].append(s[key][1])                    if key not in list(s.keys()):                        dictionary[key + "_" + ref].append(np.nan)                        dictionary[key + "_" + ref + "_error"].append(np.nan)    print(dictionary)    csvFileName = saveTo + csvName    df = pd.DataFrame(data = dictionary, columns = list(dictionary.keys()))    df.to_csv(csvFileName, index=csvIndex, header=True)    print(df)def modelFitGridToCSV(Files, path, modelList, saveTo, csvName='', csvIndex=False):    """    Parameters    ----------    Files : TYPE, required.        DESCRIPTION. The default is null. Enter either a single file or a list        of files to be evaluated.    path : TYPE, required.        DESCRIPTION. The default is null. Enter the path to where the file        being analyzed is located on your local computer as a string.    modelList : TYPE, required.        DESCRIPTION. The default is null. Enter either a single model or a list        of models to be used in the analysis of the file(s) entered.    saveTo : TYPE, required.        DESCRIPTION. The default is null. Enter the path to where you wish        the final csv file to be saved to. You can also enter the name of the        file at the end of the pathname or you can use csvName instead.    csvName : TYPE, optonal.        DESCRIPTION. The default is ''. This will be the name of the csv file.        You can also add this to the end of :saveTo: instead.    csvIndex : TYPE, optional        DESCRIPTION. The default is False. Change to True if you wish to add        an index to your final csv file.    Returns    -------    None.    """    dictionary = {"Files" : [],                  "Shortnames" : [],                  "Dates" : [],                  "RA" : [],                  "DEC" : [],                  "model" : [],                  "instrument" : [],                  "teff" : [],                  "logg" : [],                  "z" : [],                  "enrich" : [],                  "stat" : [],                  "scale" : [],                  "radius" : []}    modelFitKeyList = ["model",                  "instrument",                  "teff",                  "logg",                  "z",                  "enrich",                  "stat",                  "scale",                  "radius"]    if isinstance(Files, list) == False:        Files = [Files]    for file in Files:        givePercentage(file, Files)        name = file[11:-12]        date = file[21:-5]        p = Classify(path=path, file=file, name=name)        s = Source(path_name=path+file)        ### Part 1        try:            for i in range(len(modelList)):                dictionary["Files"].append(file)                dictionary["Shortnames"].append("J" + name)                dictionary["Dates"].append(date)                dictionary["RA"].append(s.RA)                dictionary["DEC"].append(s.DEC)        except:            print("Part 1 failed")        ### Part 2        try:            for model in modelList:                givePercentage(model, modelList)                modelFit = p.modelFitGrid(model=model)                keys = modelFitKeyList                for key in keys:                    if key in list(modelFit.keys()):                        if key == "radius":                            dictionary[key].append(modelFit[key].value)                        else:                            dictionary[key].append(modelFit[key])                    if key not in list(modelFit.keys()):                        dictionary[key].append(np.nan)        except:            print("Part 2 failed")    csvFileName = saveTo + csvName    df = pd.DataFrame(data = dictionary, columns = list(dictionary.keys()))    df.to_csv(csvFileName, index=csvIndex, header=True)    print(df)