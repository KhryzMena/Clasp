{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "###################### Insert your own paths here ######################\n",
    "\n",
    "import sys\n",
    "\n",
    "paths = []\n",
    "for path in paths:\n",
    "    if path not in sys.path:\n",
    "        sys.path.append(path)\n",
    "#print(sys.path)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# main splat import\n",
    "\n",
    "import splat as sp\n",
    "import splat.plot as splot\n",
    "import splat.photometry as sphot\n",
    "import splat.empirical as spem\n",
    "import splat.model\n",
    "\n",
    "# other useful imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import astropy.units as u\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import download_file\n",
    "import statistics\n",
    "from givePercentage import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classify class that contains methods to simplify the process of reducing data\n",
    "\n",
    "class Classify:\n",
    "\n",
    "    def __init__(self, path, file, file_type='fits', name=''):\n",
    "        '''\n",
    "        :Purpose:\n",
    "\n",
    "            To create an instance variable within the class Classify with the\n",
    "            required parameters to successfully  utilize the splat method used\n",
    "            the methods contained within\n",
    "\n",
    "        :Required Parameters:\n",
    "\n",
    "            :param path: The path to the folder that contains the file(s)\n",
    "                being analyzed\n",
    "            :param file: The name of the file being analyzed\n",
    "\n",
    "        :Optional Parameters:\n",
    "\n",
    "            :param file_type: The type of file that is being analyzed\n",
    "            :param name: The name of the object observed within the file used\n",
    "            to facilitate plotting and referencing\n",
    "\n",
    "        :Output:\n",
    "\n",
    "            N/a, constructor\n",
    "\n",
    "        :Example:\n",
    "\n",
    "            file = Classify(path='/home/Desktop/',\n",
    "                            file='spex_prism_0412+1044_160930.fits',\n",
    "                            name='0412+1044')\n",
    "\n",
    "        '''\n",
    "\n",
    "        path = path\n",
    "        filename = path + file\n",
    "        self.file = filename\n",
    "        self.file_type = file_type\n",
    "        self.name = name\n",
    "\n",
    "\n",
    "\n",
    "    def classifyByStandard(self, plot=False, file=False, average=False):\n",
    "        '''\n",
    "        :Purpose:\n",
    "\n",
    "            Determine the spectral type and uncertainty for a spectrum by\n",
    "            direct comparison to defined spectral standards. Dwarf standards\n",
    "            span M0-T9 and include the standards listed in\n",
    "            `Burgasser et al. (2006)\n",
    "            <http://adsabs.harvard.edu/abs/2006ApJ...637.1067B>`_,\n",
    "            `Kirkpatrick et al. (2010)\n",
    "            <http://adsabs.harvard.edu/abs/2010ApJS..190..100K>`_ and\n",
    "            `Cushing et al. (2011)\n",
    "            <http://adsabs.harvard.edu/abs/2011ApJ...743...50C>`_.\n",
    "            Comparison to subdwarf and extreme subdwarf standards may also be\n",
    "            done. Returns the best match or an F-test weighted mean and\n",
    "            uncertainty. There is an option to follow the procedure of\n",
    "            `Kirkpatrick et al. (2010)\n",
    "            <http://adsabs.harvard.edu/abs/2010ApJS..190..100K>`_,\n",
    "            fitting only in the 0.9-1.4 micron region.\n",
    "\n",
    "        :Required Parameters:\n",
    "\n",
    "            N/a, No parameters are required but the calling object must be an\n",
    "            instance variable of the class Classify\n",
    "\n",
    "        :Optional Parameters:\n",
    "\n",
    "            N/a, No parameters are required but the calling object must be an\n",
    "            instance variable of the class Classify\n",
    "\n",
    "        :Output:\n",
    "\n",
    "             A tuple listing the best match standard and uncertainty based on\n",
    "             F-test weighting and systematic uncertainty of 0.5 subtypes\n",
    "\n",
    "        :Example:\n",
    "\n",
    "            import splat\n",
    "            file = Classify('/home/Desktop/',\n",
    "                            'spex_prism_0412+1044_160930.fits',\n",
    "                            name='0412+1044')\n",
    "            starType = file.classifyByStandard()\n",
    "\n",
    "        '''\n",
    "\n",
    "        sp1 = splat.Spectrum(file=self.file, file_type=self.file_type,\n",
    "                             name=self.name)\n",
    "        result = splat.classifyByStandard(sp1, plot=plot, file=file,\n",
    "                                          average=average)\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "    def classifyByIndex(self, ref=\"burgasser\"):\n",
    "        '''\n",
    "        :Purpose:\n",
    "\n",
    "            Determine the spectral type and uncertainty for a spectrum based\n",
    "            on indices. Makes use of published index-SpT relations from\n",
    "            `Reid et al. (2001)\n",
    "            <http://adsabs.harvard.edu/abs/2001AJ....121.1710R>`_;\n",
    "            `Testi et al. (2001)\n",
    "            <http://adsabs.harvard.edu/abs/2001ApJ...552L.147T>`_;\n",
    "            `Allers et al. (2007)\n",
    "            <http://adsabs.harvard.edu/abs/2007ApJ...657..511A>`_; and\n",
    "            `Burgasser (2007)\n",
    "            <http://adsabs.harvard.edu/abs/2007ApJ...659..655B>`_.\n",
    "            Returns 2-element tuple containing spectral type\n",
    "            (numeric or string) and uncertainty.\n",
    "\n",
    "        :Required Parameters:\n",
    "\n",
    "            N/a, No parameters are required but the calling object must be an\n",
    "            instance variable of the class Classify\n",
    "\n",
    "        :Optional Parameters:\n",
    "\n",
    "            N/a, No parameters are required but the calling object must be an\n",
    "            instance variable of the class Classify\n",
    "\n",
    "        :Output:\n",
    "\n",
    "            The index of the star\n",
    "\n",
    "        :Example:\n",
    "\n",
    "            import splat\n",
    "            file = Classify('/home/Desktop/',\n",
    "                            'spex_prism_0412+1044_160930.fits',\n",
    "                            name='0412+1044')\n",
    "            starType = file.classifyByIndex()\n",
    "\n",
    "        '''\n",
    "\n",
    "        sp1 = splat.Spectrum(file=self.file, file_type=self.file_type,\n",
    "                             name=self.name)\n",
    "        result = splat.classifyByIndex(sp1, ref=ref)\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "    def classifyGravity(self):\n",
    "        '''\n",
    "        :Purpose:\n",
    "\n",
    "            Determine the gravity classification of a brown dwarf using the\n",
    "            method of `Allers & Liu (2013)\n",
    "            <http://adsabs.harvard.edu/abs/2013ApJ...772...79A>`_.\n",
    "\n",
    "        :Parameters:\n",
    "\n",
    "            N/a, No parameters are required but the calling object must be an\n",
    "            instance variable of the class Classify\n",
    "\n",
    "        :Output:\n",
    "\n",
    "            Either a string specifying the gravity classification or a\n",
    "            dictionary specifying the gravity scores for each index\n",
    "\n",
    "        :Example:\n",
    "\n",
    "            >>> import splat\n",
    "            >>> file = Classify('/home/Desktop/',\n",
    "                                'spex_prism_0412+1044_160930.fits',\n",
    "                                name='0412+1044')\n",
    "            >>> starType = file.classifyGravity()\n",
    "\n",
    "        '''\n",
    "\n",
    "        sp1 = splat.Spectrum(file=self.file, file_type=self.file_type,\n",
    "                             name=self.name)\n",
    "        try:\n",
    "            result = splat.classifyGravity(sp1)\n",
    "            return result\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "\n",
    "    def measureIndex(self, num_init, num_fin, den_init, den_fin):\n",
    "        '''\n",
    "        :Purpose:\n",
    "\n",
    "            Measure an index on a spectrum based on defined methodology\n",
    "            measure method can be mean, median, integrate\n",
    "            index method can be ratio = 1/2, valley = 1-2/3, OTHERS\n",
    "\n",
    "        :Required Parameters:\n",
    "\n",
    "            :param num_init: The initial value for the range in the numerator\n",
    "            :param num_fin: The final value for the range in the numerator\n",
    "            :param den_init: The initial value for the range in the denominator\n",
    "            :param den_fin: The final value for the range in the denominator\n",
    "\n",
    "        :Output:\n",
    "\n",
    "            Index value and uncertainty\n",
    "\n",
    "        :Example:\n",
    "\n",
    "            >>> import splat\n",
    "            >>> file = Classify('/home/Desktop/',\n",
    "                                'spex_prism_0412+1044_160930.fits',\n",
    "                                name='0412+1044')\n",
    "            >>> starType = file.measureIndex(1.1, 1.2, 1.22, 1.32)\n",
    "\n",
    "        '''\n",
    "\n",
    "        sp1 = splat.Spectrum(file=self.file, file_type=self.file_type,\n",
    "                             name=self.name)\n",
    "        result = splat.measureIndex(sp1, [[num_init, num_fin],[den_init, den_fin]])\n",
    "        return result\n",
    "\n",
    "\n",
    "    def measureIndexSet(self, ref='burgasser'):\n",
    "        '''\n",
    "        :Purpose:\n",
    "\n",
    "            Measures indices of ``sp`` from specified sets.\n",
    "\n",
    "        :Required Input:\n",
    "\n",
    "            :param ref='burgasser': string identifying the index set\n",
    "                you want to measure, as contained in the variable\n",
    "                splat.INDEX_SETS\n",
    "\n",
    "        :Output:\n",
    "\n",
    "            A dictionary containing the names of each index pointed\n",
    "            to tuple of (measurement,uncertainty)\n",
    "\n",
    "        :Example:\n",
    "\n",
    "            import splat\n",
    "            file = Classify('/home/Desktop/',\n",
    "                            'spex_prism_0412+1044_160930.fits',\n",
    "                            name='0412+1044')\n",
    "            file.measureIndexSet(ref='burgasser')\n",
    "\n",
    "        '''\n",
    "\n",
    "        sp1 = splat.Spectrum(file=self.file, file_type=self.file_type,\n",
    "                             name=self.name)\n",
    "        result = splat.measureIndexSet(sp1, ref=ref)\n",
    "        return result\n",
    "\n",
    "\n",
    "    def compareSpectrum(self, statistic):\n",
    "        '''\n",
    "        :Purpose:\n",
    "\n",
    "            Compare two spectra against each other within the same category of\n",
    "            star with the statistic='chisqr', 'stddev', or 'absdev'\n",
    "\n",
    "        :Input:\n",
    "\n",
    "            :param statistic: Possible inputs are 'chisqr', 'stddev', and '\n",
    "                absdev'\n",
    "\n",
    "        :Output:\n",
    "\n",
    "            The value of the desired statistic as well as the optimal scale\n",
    "            factor.\n",
    "\n",
    "        :Example:\n",
    "\n",
    "            import splat\n",
    "            file = Classify('/home/Desktop/',\n",
    "                            'spex_prism_0412+1044_160930.fits',\n",
    "                            name='0412+1044')\n",
    "            starType = file.compareSpectrum('chisqr')\n",
    "\n",
    "        '''\n",
    "\n",
    "        sp1 = splat.Spectrum(file=self.file, file_type=self.file_type,\n",
    "                             name=self.name)\n",
    "        result = splat.classifyByStandard(sp1)\n",
    "        sp2 = splat.getSpectrum(spt=result[0], lucky=True)[0]\n",
    "        sp1.normalize()\n",
    "        sp2.normalize()\n",
    "\n",
    "        stat = splat.compareSpectra(sp1, sp2, statistic=statistic)\n",
    "\n",
    "        return stat\n",
    "    \n",
    "\n",
    "    def typeToNum(self, value):\n",
    "        \"\"\"\n",
    "        :Purpose:\n",
    "\n",
    "            Converts between string and numeric spectral types, with the option\n",
    "            of specifying the class prefix/suffix and uncertainty tags\n",
    "\n",
    "        :Required Input:\n",
    "\n",
    "            No input required but the value must first be converted to type\n",
    "            with classifyByStandard or classifyByIndex and select the 0th value\n",
    "\n",
    "        :Outputs:\n",
    "\n",
    "            The number or string of a spectral type\n",
    "\n",
    "        :Example:\n",
    "\n",
    "            import splat\n",
    "            file = Classify('/home/Desktop/',\n",
    "                            'spex_prism_0412+1044_160930.fits',\n",
    "                            name='0412+1044')[0]\n",
    "            r = file.classifyByStandard()\n",
    "            file.typeToNum(r[0])\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        num = splat.typeToNum(str(value))\n",
    "        return num\n",
    "\n",
    "\n",
    "\n",
    "    def modelFitGrid(self, model, teff_range=[400,4000], plot=False,\n",
    "                     file=\"fit1507\", calName='2MASS J', calNum=12.32,\n",
    "                     absolute=True, verbose=False):\n",
    "        \"\"\"\n",
    "        :Purpose:\n",
    "\n",
    "            Fits a spectrum to a grid of atmosphere models, reports\n",
    "            the best-fit and weighted average parameters, and returns\n",
    "            either a dictionary with the best-fit model parameters or\n",
    "            the model itself scaled to the optimal scaling factor. If\n",
    "            spectrum is absolutely flux calibrated with the\n",
    "            `fluxcalibrate()`_ method, the routine will also calculate\n",
    "            the equivalent radii of the source. In addition, an input\n",
    "            radius can be used to provide an additional constraint on\n",
    "            the model\n",
    "\n",
    "        :Required Parameters:\n",
    "\n",
    "            :param teff_range: set to the range of temperatures over which\n",
    "                model fitting will be done\n",
    "            :param model: The model by which the spectrum will be\n",
    "                compared to\n",
    "\n",
    "        :List of Models:\n",
    "\n",
    "            [\"btcond\",\n",
    "            \"btnextgen\",\n",
    "            \"btsettl08\",\n",
    "            \"btsettl15\",\n",
    "            \"burrows06\",\n",
    "            \"cond01\",\n",
    "            \"drift\",\n",
    "            \"dusty01\",\n",
    "            \"madhusudhan11\",\n",
    "            \"morley12\",\n",
    "            \"morley14\",\n",
    "            \"saumon12\",\n",
    "            \"sonora18\",\n",
    "            \"veyette\"]\n",
    "\n",
    "        :Output:\n",
    "\n",
    "            Output is a dictionary containing the best-fit model\n",
    "            parameters: model name, teff, logg, z, fsed, kzz, cloud\n",
    "            and slit, as well as the scaling factor for the model and\n",
    "            comparison statistic.\n",
    "\n",
    "        :Example:\n",
    "\n",
    "            >>> import splat\n",
    "            >>> from clasp import *\n",
    "            >>> file = Classify('/home/Desktop/',\n",
    "                                'spex_prism_0412+1044_160930.fits',\n",
    "                                name='0412+1044')\n",
    "            >>> file.modelFitGrid(model=\"Saumon08\")\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        sp1 = splat.Spectrum(file=self.file, file_type=self.file_type,\n",
    "                             name=self.name)\n",
    "        sp1.fluxCalibrate(calName, calNum, absolute=absolute)\n",
    "        result = splat.model.modelFitGrid(sp1, plot=plot, file=file,\n",
    "                                          teff_range=teff_range, modelset=model,\n",
    "                                          verbose=verbose)\n",
    "        return result\n",
    "\n",
    "\n",
    "    def typeToTeff(self, uncertainty=[0.0], reference='stephens09',\n",
    "                   nsamples=100, reverse=False, string=False, verbose=False):\n",
    "        \"\"\"\n",
    "        :Purpose:\n",
    "\n",
    "            Returns an effective temperature (Teff) and its uncertainty\n",
    "            for a given spectral type (or vice versa) based on an\n",
    "            empirical relation\n",
    "\n",
    "        :Required Inputs:\n",
    "\n",
    "            A single or array of either spectral types or effective\n",
    "            temperatures (reverse). If spectral types, these can be\n",
    "            ints, floats or strings from 0 (K0) and 49.0 (Y9).If\n",
    "            temperatures, these can be ints or floats and assumed to\n",
    "            be in units of Kelvin.\n",
    "            Note: you must set reverse=True to convert temperature to\n",
    "            spectral type.\n",
    "\n",
    "        :Optional Inputs:\n",
    "\n",
    "            :param uncertainty: uncertainty of spectral type/temperature\n",
    "                (default = 0.001; also 'unc', 'spt_e')\n",
    "            :param reference: Teff/SpT relation used to compute the effective\n",
    "                temperature (also 'set'). Options are:\n",
    "\n",
    "            - *stephens* (default): Teff/SpT relation from `Stephens et al.\n",
    "                (2009) <http://adsabs.harvard.edu/abs/2009ApJ...702..154S>`_.\n",
    "                Allowed spectral type range is M6 to T8 and uses alternate\n",
    "                coefficients for L3 to T8.\n",
    "\n",
    "            - *golimowski*: Teff/SpT relation from `Golimowski et al. (2004)\n",
    "                <http://adsabs.harvard.edu/abs/2004AJ....127.3516G>`_.\n",
    "                Allowed spectral type range is M6 to T8.\n",
    "\n",
    "            - *looper*: Teff/SpT relation from `Looper et al. (2008)\n",
    "                <http://adsabs.harvard.edu/abs/2008ApJ...685.1183L>`_.\n",
    "                Allowed spectral type range is L0 to T8.\n",
    "\n",
    "            - *marocco*: Teff/SpT relation from `Marocco et al. (2013)\n",
    "                <http://adsabs.harvard.edu/abs/2013AJ....146..161M>`_.\n",
    "                Allowed spectral type range is M7 to T8.\n",
    "\n",
    "            - *filippazzo*: Teff/SpT relation from Filippazzo et al. (2015)\n",
    "                <http://adsabs.harvard.edu/abs/2015ApJ...810..158F>`_.\n",
    "                Allowed spectral type range is M6 to T9.\n",
    "\n",
    "            - *faherty*: Teff/SpT relation from Faherty et al. (2016)\n",
    "                <http://adsabs.harvard.edu/abs/2016ApJS..225...10F>`_.\n",
    "                This relation is defined for normal dwarfs (M7 < SpT < T8),\n",
    "                young dwarfs (``-young`` and ``-young2``, M7 < SpT < L7),\n",
    "                and young dwarfs in groups (``-group``, M7 < SpT < L7)\n",
    "\n",
    "            - *dupuy*: Teff/SpT relation from Dupuy et al. (2017).\n",
    "                This relation is defined for Saumon & Marley (2008) models\n",
    "                (``-saumon``, L1.5 < SpT < T5) and Lyon models\n",
    "                (``-lyon``, M7 < SpT < T5)\n",
    "\n",
    "            :param reverse: set to True to convert effective temperature to spectral type (default=False)\n",
    "            :param nsamples: number of samples to use in Monte Carlo error estimation (default=100)\n",
    "\n",
    "        :Output:\n",
    "\n",
    "            A 2-element tuple containing the Teff/SpT and its uncertainty\n",
    "        \"\"\"\n",
    "\n",
    "        m0 = splat.typeToNum('M0')\n",
    "        m6 = splat.typeToNum('M6')\n",
    "        t8 = splat.typeToNum('T8')\n",
    "\n",
    "        spt = self.classifyByStandard()\n",
    "        num = self.typeToNum(spt[0])\n",
    "\n",
    "        if m6 <= num and t8 > num:\n",
    "            teff = splat.empirical.typeToTeff(var=num, uncertainty=uncertainty,\n",
    "                                              reference='stephens',\n",
    "                                              nsamples=nsamples,\n",
    "                                              reverse=reverse, string=string,\n",
    "                                              verbose=verbose)[0]\n",
    "            teff = str(teff)[:-1]\n",
    "            teff = float(teff)\n",
    "            return teff\n",
    "\n",
    "        if m0 <= num and m6 > num:\n",
    "            teff = splat.empirical.typeToTeff(var=num, uncertainty=uncertainty,\n",
    "                                              reference='pecaut',\n",
    "                                              nsamples=nsamples,\n",
    "                                              reverse=reverse, string=string,\n",
    "                                              verbose=verbose)[0]\n",
    "            teff = str(teff)[:-1]\n",
    "            teff = float(teff)\n",
    "            return teff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Source:\n",
    "    #initial function will take the information required to get the coordinates from the fits file\n",
    "    # Credit: Christopher Danner\n",
    "\n",
    "\n",
    "    def __init__(self, path_name):\n",
    "        Header = fits.open(path_name)[0].header\n",
    "        for x in range(len(list(Header))):\n",
    "            if 'RA' == list(Header)[x] or '_RA' in list(Header)[x]:\n",
    "                RA_header = list(Header)[x]\n",
    "            if 'DEC' == list(Header)[x] or '_DEC' in list(Header)[x]:\n",
    "                DEC_header = list(Header)[x]\n",
    "\n",
    "        try:\n",
    "            self.RA = Header[RA_header]\n",
    "            self.DEC = Header[DEC_header]\n",
    "        except UnboundLocalError as error:\n",
    "            #This means that RA_header or DEC_header did not get a value bound to them.  Could either mean that the Header does\n",
    "            #not contain an RA or DEC value, or that the RA/DEC value is not recognized\n",
    "            print(list(Header))\n",
    "            print(\"The function could not find a RA or DEC label in the above Header.  Double check to make sure that the \\ given file contains the coordinates\")\n",
    "\n",
    "\n",
    "    def set_unit(self):\n",
    "        if ':' in self.RA:\n",
    "            self.RA = convert_coords(self.RA, self.DEC)[0]\n",
    "            self.DEC = convert_coords(self.RA, self.DEC)[1]\n",
    "            self.unit = 'degree'\n",
    "        else:\n",
    "            self.unit = 'degree'\n",
    "\n",
    "    def cat_num(self):\n",
    "        self.given_catalogs = []\n",
    "        for x in range(len(catalogs)):\n",
    "            if 'No data' in cat_results(self.RA, self.DEC, cat = catalogs[x],\n",
    "                                        unit = self.unit):\n",
    "                continue\n",
    "            else:\n",
    "                self.given_catalogs.append(catalogs[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexDicToCSV(path='', csvName = '', ref='burgasser', fileNameList=[],\n",
    "                  index=False, header=True):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pathName : TYPE, optional. Write the path to where the csv file will be\n",
    "    saved\n",
    "        DESCRIPTION. The default is ''.\n",
    "    ref : TYPE, optional\n",
    "        DESCRIPTION. The default is 'burgasser'.\n",
    "        Other options are: ['bardalez', 'burgasser', 'tokunaga', 'reid',\n",
    "                            'geballe', 'allers', 'testi', 'slesnick', 'mclean',\n",
    "                            'rojas']\n",
    "    fileNameList : TYPE, optional\n",
    "        DESCRIPTION. The default is []. Give a list of the names of the files\n",
    "        to be analyzed.\n",
    "    index : TYPE, optional\n",
    "        DESCRIPTION. The default is False. To put a index in the final csv file\n",
    "    header : TYPE, optional.\n",
    "        DESCRIPTION. The default is True. To put a header in the final csv file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None. A csv with the results is saved in the directory listed in :param:\n",
    "        pathName\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> import splat\n",
    "    >>> from clasp import *\n",
    "    >>> fileNameList = [\"spex_prism_0004-1336_160922.fits\",\n",
    "                        \"spex_prism_0004-2604_160803.fits\"]\n",
    "    >>> indexDicToCSV(pathName=\"/Users/home/Desktop/\", ref=\"allers\",\n",
    "                      fileNameList=fileNameList)\n",
    "\n",
    "    \"\"\"\n",
    "    indexSet = []\n",
    "    for i in fileNameList:\n",
    "        file = Classify(path=path, file=str(i))\n",
    "        inter = file.measureIndexSet(ref=ref)\n",
    "        indexSet.append(inter)\n",
    "\n",
    "    categories = ['FileName']\n",
    "    for key in indexSet[0].keys():\n",
    "        if key not in categories:\n",
    "            categories.append(key)\n",
    "            categories.append(key + ' err')\n",
    "\n",
    "    pathName = path + csvName\n",
    "    csvFileName = pathName + \"ref='\" + ref + \"'.csv\"\n",
    "    print(csvFileName)\n",
    "    dictionary={}\n",
    "    dictionary['FileName']=fileNameList\n",
    "\n",
    "    for item in categories:\n",
    "        if 'FileName' in item:\n",
    "            continue\n",
    "        elif 'err' in item:\n",
    "            dictionary[item]=[]\n",
    "        elif 'err' not in item:\n",
    "            dictionary[item]=[]\n",
    "\n",
    "    for dic in indexSet:\n",
    "        for item in categories:\n",
    "            if 'FileName' in item:\n",
    "                continue\n",
    "            elif 'err' in item:\n",
    "                dictionary[item].append(dic[item[:-4]][1])\n",
    "            elif 'err' not in item:\n",
    "                dictionary[item].append(dic[item][0])\n",
    "\n",
    "    df = pd.DataFrame(dictionary, columns=categories)\n",
    "    df.to_csv(csvFileName, index=index, header=header)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareStarType(pathToFile, file, pathToSave, file_type='fits', name='',\n",
    "                    plt_xLim=[0.8,2.4], plt_yLim=[0,1.2], verbose=False,\n",
    "                    plot=False):\n",
    "    pathToFile = str(pathToFile + file)\n",
    "    sp1 = splat.Spectrum(file=pathToFile, file_type=file_type, name=name)\n",
    "    result = splat.classifyByStandard(sp1)\n",
    "    sp2 = splat.getSpectrum(spt=result[0], lucky=True)[0]\n",
    "    sp1.normalize()\n",
    "    sp2.normalize()\n",
    "\n",
    "    splat.compareSpectra(sp1, sp2, verbose=verbose, plot=plot,\n",
    "                         file=str(pathToSave + file + '.png'))\n",
    "    '''\n",
    "    plt.plot(sp1.wave, sp1.flux, 'b-')\n",
    "    plt.plot(sp2.wave, sp2.flux, 'g-')\n",
    "    plt.legend([file, sp2.name])\n",
    "    plt.xlim(plt_xLim)\n",
    "    plt.ylim(plt_yLim)\n",
    "    plt.xlabel('Wavelength (micron)')\n",
    "    plt.ylabel('Normalized Flux Density')\n",
    "    plt.show()\n",
    "    plt.savefig(file + '.png', bbox_inches='tight')\n",
    "    '''\n",
    "    print(\"The star is an \" + result[0] + \" type star.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareStarIndex(file, file_type='fits', name='', plt_xLim=[0.8,2.4],\n",
    "                     plt_yLim=[0,1.2]):\n",
    "    sp1 = splat.Spectrum(file=file, file_type=file_type, name=name)\n",
    "    result = splat.classifyByIndex(sp1)\n",
    "    starType = result[0][:-2]\n",
    "    sp2 = splat.getSpectrum(spt=starType, lucky=True)[0]\n",
    "    sp1.normalize()\n",
    "    sp2.normalize()\n",
    "\n",
    "    plt.plot(sp1.wave, sp1.flux, 'b-')\n",
    "    plt.plot(sp2.wave, sp2.flux, 'g-')\n",
    "    plt.legend([sp1.name, sp2.name])\n",
    "    plt.xlim(plt_xLim)\n",
    "    plt.ylim(plt_yLim)\n",
    "    plt.xlabel('Wavelength (micron)')\n",
    "    plt.ylabel('Normalized Flux Density')\n",
    "\n",
    "    print(\"The star is an \" + result[0] + \" type star.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicToCSV(listOfDics, path='', fileTitle='', fileNameList=[], numOfModels=1,\n",
    "             index=False, header=True, fileName=True, err=False):\n",
    "    # Create categories list\n",
    "    if fileName==True:\n",
    "        categories = ['FileName']\n",
    "    if fileName==False:\n",
    "        categories=[]\n",
    "\n",
    "    # Create error columns is err==True\n",
    "    if err==True:\n",
    "        for key in listOfDics[0].keys():\n",
    "            if key not in categories:\n",
    "                categories.append(key)\n",
    "                categories.append(key + ' err')\n",
    "    if err==False:\n",
    "        for key in listOfDics[0].keys():\n",
    "            if key not in categories:\n",
    "                categories.append(key)\n",
    "\n",
    "    # Create empty dictionary\n",
    "    dictionary={}\n",
    "    # Check if fileNameList is empty, if so do not add 'FileName' column, else:\n",
    "    #do\n",
    "    if not fileNameList:\n",
    "        pass\n",
    "    else:\n",
    "        dictionary['FileName']=[]\n",
    "\n",
    "    for item in categories:\n",
    "        if 'FileName' in item:\n",
    "            continue\n",
    "        else:\n",
    "            dictionary[item]=[]\n",
    "    print(dictionary)\n",
    "\n",
    "    for fname in fileNameList:\n",
    "        for i in range(numOfModels):\n",
    "            dictionary['FileName'].append(fname)\n",
    "\n",
    "    for dic in listOfDics:\n",
    "        #print(dictionary)\n",
    "        for item in categories:\n",
    "            if 'FileName' in item:\n",
    "                continue\n",
    "            if item not in dic:\n",
    "                dictionary[item].append(np.nan)\n",
    "            elif 'err' in item:\n",
    "                dictionary[item].append(dic[item[:-4]][1])\n",
    "            elif 'err' not in item:\n",
    "                dictionary[item].append(dic[item])\n",
    "\n",
    "    print(dictionary)\n",
    "    csvFileName = str(path) + str(fileTitle)\n",
    "    df = pd.DataFrame(dictionary, columns=categories)\n",
    "    df.to_csv(csvFileName, index=index, header=header)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePlot(model, modelString, dictionary={}, voice=False):\n",
    "    if len(model) > 0:\n",
    "        typeToTeff_list = []\n",
    "        for model_key in model.keys():\n",
    "            typeToTeff_list.append(dictionary[model_key])\n",
    "\n",
    "        model = list(model.values())\n",
    "        difference = []\n",
    "        i = 0\n",
    "        while i < len(typeToTeff_list):\n",
    "            diff = typeToTeff_list[i] - model[i]\n",
    "            difference.append(diff)\n",
    "            i+=1\n",
    "\n",
    "        difference.sort()\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_axes([0.1, 0.65, 0.8, .4],\n",
    "                        xlim=(0, 5000), ylim=(0, 5000))\n",
    "        ax2 = fig.add_axes([0.1, 0.1, 0.8, .4],\n",
    "                        ylim=(0, 20))\n",
    "\n",
    "        x = np.linspace(0, 5000)\n",
    "        ax1.plot(typeToTeff_list, model, 'b.', label=modelString)\n",
    "        ax1.plot(x, x, 'r--', label='$y = x$')\n",
    "        ax1.set_xlabel('Teffs from typeToTeffs')\n",
    "        ax1.set_ylabel('Teffs from modelFitGrid')\n",
    "        ax1.legend()\n",
    "\n",
    "        ax2.hist(difference, bins= 20, label='Difference')\n",
    "        ax2.set_ylabel('Difference = Teff(SpT)-Teff(model)')\n",
    "        median = '{:.0f}'.format(statistics.median(difference))\n",
    "        stdev = '{:.0f}'.format(statistics.stdev(difference))\n",
    "        ratio = '{:.1f}'.format(len(model) / stdev)\n",
    "        #plt.text(median, 0.2, str(median))\n",
    "        plt.text(min(difference), 15, \"Difference = Teff(SpT)-Teff(model)\" +\n",
    "                 '\\nstdev = ' + str(stdev) + ' K' + '\\nmedian = ' + str(median)\n",
    "                 + ' K' + \"\\nNo. of values = \" + str(len(model)) + \"\\nRatio = \"\n",
    "                 + str(ratio), horizontalalignment='left',\n",
    "                 verticalalignment='center')\n",
    "        plt.savefig(modelString + '.png', bbox_inches='tight')\n",
    "\n",
    "        print()\n",
    "\n",
    "    if len(model) == 0:\n",
    "        print(\"No Data for \" + modelString)\n",
    "        if voice == True:\n",
    "            import os\n",
    "            os.system(\"say 'No data for ' \" + modelString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrumToCSV(Files, path, saveTo, csvName='', classifyByIndex = True,\n",
    "                  average=True, standard=True, gravity=True, chisqr=False,\n",
    "                  stddev=False, absdev=False, csvIndex=False):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Files : TYPE, required\n",
    "        DESCRIPTION. The default is []. Enter the list of file names to be\n",
    "        added to the csv.\n",
    "\n",
    "    path : TYPE, required\n",
    "        DESCRIPTION. The default is ''. Enter the path to the files being\n",
    "        analyzed.\n",
    "\n",
    "    csvName : TYPE, required\n",
    "        DESCRIPTION. The default is ''. Enter the name you wish the csv file to\n",
    "        be named.\n",
    "\n",
    "    classifyByIndex : TYPE, optional\n",
    "        DESCRIPTION. The default is True. This adds the values returned by\n",
    "        splat.classifyByIndex to the csv file with references = [\"burgasser\",\n",
    "                                                                 \"allers\",\n",
    "                                                                 \"reid\"]\n",
    "\n",
    "    average : TYPE, optional\n",
    "        DESCRIPTION. The default is True. By changing this to False the\n",
    "        classifyByStandard method returns the \"Best Standard\" where setting\n",
    "        this to True returns the \"Mean Standard\"\n",
    "\n",
    "    Standard : TYPE, optional\n",
    "        DESCRIPTION. The default is True.\n",
    "\n",
    "    Gravity : TYPE, optional\n",
    "        DESCRIPTION. The default is True.\n",
    "\n",
    "    chisqr : TYPE, optional\n",
    "        DESCRIPTION. The default is True.\n",
    "\n",
    "    stddev : TYPE, optional\n",
    "        DESCRIPTION. The default is False.\n",
    "\n",
    "    absdev : TYPE, optional\n",
    "        DESCRIPTION. The default is False.\n",
    "\n",
    "    csvIndex : TYPE, optional\n",
    "        DESCRIPTION. The defualt is False. Change to True if you wish to have\n",
    "        an index in the final csv file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    CSV file containing the classificiation information of the spectra\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    dictionary = {}\n",
    "\n",
    "    dictionary[\"Files\"] = Files\n",
    "    dictionary[\"Shortnames\"] = []\n",
    "    dictionary[\"Dates\"] = []\n",
    "    dictionary[\"RA\"] = []\n",
    "    dictionary[\"DEC\"] = []\n",
    "\n",
    "    if isinstance(Files, list) == False:\n",
    "        Files = [Files]\n",
    "\n",
    "    if standard == True:\n",
    "        dictionary[\"Standard\"] = []\n",
    "        dictionary[\"Standard_error\"] = []\n",
    "\n",
    "    if gravity == True:\n",
    "        dictionary[\"Gravity\"] = []\n",
    "\n",
    "    if chisqr == True:\n",
    "        dictionary[\"chisqr\"] = []\n",
    "        dictionary[\"chisqr_error\"] = []\n",
    "\n",
    "    if stddev == True:\n",
    "        dictionary[\"stddev\"] = []\n",
    "        dictionary[\"stddev_error\"] = []\n",
    "\n",
    "    if absdev == True:\n",
    "        dictionary[\"absdev\"] = []\n",
    "        dictionary[\"absdev_error\"] = []\n",
    "\n",
    "    if classifyByIndex == True:\n",
    "            indexList = [\"burgasser\", \"allers\", \"reid\"]\n",
    "            dictionary[\"Index_burgasser\"] = []\n",
    "            dictionary[\"Index_burgasser_err\"] = []\n",
    "            dictionary[\"Index_allers\"] = []\n",
    "            dictionary[\"Index_allers_err\"] = []\n",
    "            dictionary[\"Index_reid\"] = []\n",
    "            dictionary[\"Index_reid_err\"] = []\n",
    "\n",
    "    for file in Files:\n",
    "        givePercentage(file, Files)\n",
    "        name = file[11:-12]\n",
    "        date = file[21:-5]\n",
    "        p = Classify(path=path, file=file, name=name)\n",
    "        s = Source(path_name=path+file)\n",
    "        dictionary[\"Shortnames\"].append(\"J\" + name)\n",
    "        dictionary[\"Dates\"].append(date)\n",
    "        dictionary[\"RA\"].append(s.RA)\n",
    "        dictionary[\"DEC\"].append(s.DEC)\n",
    "\n",
    "        if standard == True:\n",
    "            try:\n",
    "                #standard = p.classifyByStandard()\n",
    "                dictionary[\"Standard\"].append(p.classifyByStandard(average=average)[0])\n",
    "                dictionary[\"Standard_error\"].append(p.classifyByStandard(average=average)[1])\n",
    "                directories = os.listdir(saveTo)\n",
    "                if \"StandardPlots\" not in directories:\n",
    "                    os.mkdir(saveTo + \"StandardPlots\")\n",
    "                p.classifyByStandard(file=saveTo + \"StandardPlots/\" + file[:-5] + \"_classification.png\", plot=True)\n",
    "\n",
    "            except:\n",
    "                dictionary[\"Standard\"].append(np.nan)\n",
    "                dictionary[\"Standard_error\"].append(np.nan)\n",
    "\n",
    "        if gravity == True:\n",
    "            try:\n",
    "                dictionary[\"Gravity\"].append(p.classifyGravity())\n",
    "\n",
    "            except:\n",
    "                dictionary[\"Gravity\"].append(np.nan)\n",
    "\n",
    "        if classifyByIndex == True:\n",
    "            try:\n",
    "                #burgasser = p.classifyByIndex(ref=\"burgasser\")\n",
    "                dictionary[\"Index_burgasser\"].append(p.classifyByIndex(ref=\"burgasser\")[0])\n",
    "                dictionary[\"Index_burgasser_err\"].append(p.classifyByIndex(ref=\"burgasser\")[1])\n",
    "\n",
    "            except:\n",
    "                dictionary[\"Index_burgasser\"].append(np.nan)\n",
    "                dictionary[\"Index_burgasser_err\"].append(np.nan)\n",
    "\n",
    "            try:\n",
    "                #allers = p.classifyByIndex(ref=\"allers\")\n",
    "                dictionary[\"Index_allers\"].append(p.classifyByIndex(ref=\"allers\")[0])\n",
    "                dictionary[\"Index_allers_err\"].append(p.classifyByIndex(ref=\"allers\")[1])\n",
    "\n",
    "            except:\n",
    "                dictionary[\"Index_allers\"].append(np.nan)\n",
    "                dictionary[\"Index_allers_err\"].append(np.nan)\n",
    "\n",
    "            try:\n",
    "                #reed = p.classifyByIndex(ref=\"reed\")\n",
    "                dictionary[\"Index_reid\"].append(p.classifyByIndex(ref=\"reid\")[0])\n",
    "                dictionary[\"Index_reid_err\"].append(p.classifyByIndex(ref=\"reid\")[1])\n",
    "\n",
    "            except:\n",
    "                dictionary[\"Index_reid\"].append(np.nan)\n",
    "                dictionary[\"Index_reid_err\"].append(np.nan)\n",
    "\n",
    "        if chisqr == True:\n",
    "            try:\n",
    "                #chisqr = p.compareSpectrum(\"chisqr\")\n",
    "                dictionary[\"chisqr\"].append(p.compareSpectrum(\"chisqr\")[0])\n",
    "                dictionary[\"chisqr_error\"].append(p.compareSpectrum(\"chisqr\")[1])\n",
    "\n",
    "            except:\n",
    "                dictionary[\"chisqr\"].append(np.nan)\n",
    "                dictionary[\"chisqr_error\"].append(np.nan)\n",
    "\n",
    "        if stddev == True:\n",
    "            try:\n",
    "                #stddev = p.compareSpectrum(\"stddev\")\n",
    "                dictionary[\"stddev\"].append(p.compareSpectrum(\"stddev\")[0])\n",
    "                dictionary[\"stddev_error\"].append(p.compareSpectrum(\"stddev\")[1])\n",
    "\n",
    "            except:\n",
    "                dictionary[\"stddev\"].append(np.nan)\n",
    "                dictionary[\"stddev_error\"].append(np.nan)\n",
    "\n",
    "        if absdev == True:\n",
    "            try:\n",
    "                #absdev = p.compareSpectrum(\"absdev\")\n",
    "                dictionary[\"absdev\"].append(p.compareSpectrum(\"absdev\")[0])\n",
    "                dictionary[\"absdev_error\"].append(p.compareSpectrum(\"absdev\")[1])\n",
    "\n",
    "            except:\n",
    "                dictionary[\"absdev\"].append(np.nan)\n",
    "                dictionary[\"absdev_error\"].append(np.nan)\n",
    "\n",
    "    #print(dictionary)\n",
    "    csvFileName = saveTo + csvName\n",
    "    df = pd.DataFrame(data = dictionary, columns = list(dictionary.keys()))\n",
    "    df.to_csv(csvFileName, index=csvIndex, header=True)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexToCSV(Files, path, saveTo, csvName='', indexSet = True, csvIndex=False):\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Files : TYPE, required.\n",
    "        DESCRIPTION. The default is null. Enter either a single file or a list\n",
    "        of files to be evaluated.\n",
    "\n",
    "    path : TYPE, required.\n",
    "        DESCRIPTION. The default is null. Enter the path to where the file\n",
    "        being analyzed is located on your local computer as a string.\n",
    "\n",
    "    saveTo : TYPE, required.\n",
    "        DESCRIPTION. The default is null. Enter the path to where you wish\n",
    "        the final csv file to be saved to. You can also enter the name of the\n",
    "        file at the end of the pathname or you can use csvName instead.\n",
    "\n",
    "    csvName : TYPE, optonal.\n",
    "        DESCRIPTION. The default is ''. This will be the name of the csv file.\n",
    "        You can also add this to the end of :saveTo: instead.\n",
    "\n",
    "    indexSet : TYPE, optional\n",
    "        DESCRIPTION. The default is True. This adds the values returned by\n",
    "        splat.measureIndexSet to the csv file with references = [\"burgasser\",\n",
    "                                                                 \"allers\",\n",
    "                                                                 \"geballe\",\n",
    "                                                                 \"testi\",\n",
    "                                                                 \"reid\"]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A csv file containing the values returned by splat.classifyByIndex and\n",
    "    splat.measureIndexSet in the directory defined in :saveTo:\n",
    "\n",
    "    \"\"\"\n",
    "    dictionary = {}\n",
    "\n",
    "    dictionary[\"Files\"] = Files\n",
    "    dictionary[\"Shortnames\"] = []\n",
    "    dictionary[\"Dates\"] = []\n",
    "    dictionary[\"RA\"] = []\n",
    "    dictionary[\"DEC\"] = []\n",
    "\n",
    "    if isinstance(Files, list) == False:\n",
    "        Files = [Files]\n",
    "\n",
    "    for file in Files:\n",
    "        givePercentage(file, Files)\n",
    "        name = file[11:-12]\n",
    "        date = file[21:-5]\n",
    "        p = Classify(path=path, file=file, name=name)\n",
    "        s = Source(path_name=path+file)\n",
    "        dictionary[\"Shortnames\"].append(\"J\" + name)\n",
    "        dictionary[\"Dates\"].append(date)\n",
    "        dictionary[\"RA\"].append(s.RA)\n",
    "        dictionary[\"DEC\"].append(s.DEC)\n",
    "\n",
    "\n",
    "        if indexSet == True:\n",
    "            indexSetList = [\"burgasser\", \"allers\", \"geballe\", \"reid\", \"testi\"]\n",
    "            for ref in indexSetList:\n",
    "                s = p.measureIndexSet(ref=ref)\n",
    "                keys = list(s.keys())\n",
    "                for key in keys:\n",
    "                    if str(key + \"_\" + ref) not in list(dictionary.keys()):\n",
    "                        dictionary[key + \"_\" + ref] = []\n",
    "                        dictionary[key + \"_\" + ref + \"_error\"] = []\n",
    "\n",
    "                    if key in list(s.keys()):\n",
    "                        dictionary[key + \"_\" + ref].append(s[key][0])\n",
    "                        dictionary[key + \"_\" + ref + \"_error\"].append(s[key][1])\n",
    "\n",
    "                    if key not in list(s.keys()):\n",
    "                        dictionary[key + \"_\" + ref].append(np.nan)\n",
    "                        dictionary[key + \"_\" + ref + \"_error\"].append(np.nan)\n",
    "\n",
    "    print(dictionary)\n",
    "    csvFileName = saveTo + csvName\n",
    "    df = pd.DataFrame(data = dictionary, columns = list(dictionary.keys()))\n",
    "    df.to_csv(csvFileName, index=csvIndex, header=True)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelFitGridToCSV(Files, path, modelList, saveTo, csvName='', csvIndex=False):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Files : TYPE, required.\n",
    "        DESCRIPTION. The default is null. Enter either a single file or a list\n",
    "        of files to be evaluated.\n",
    "\n",
    "    path : TYPE, required.\n",
    "        DESCRIPTION. The default is null. Enter the path to where the file\n",
    "        being analyzed is located on your local computer as a string.\n",
    "\n",
    "    modelList : TYPE, required.\n",
    "        DESCRIPTION. The default is null. Enter either a single model or a list\n",
    "        of models to be used in the analysis of the file(s) entered.\n",
    "\n",
    "    saveTo : TYPE, required.\n",
    "        DESCRIPTION. The default is null. Enter the path to where you wish\n",
    "        the final csv file to be saved to. You can also enter the name of the\n",
    "        file at the end of the pathname or you can use csvName instead.\n",
    "\n",
    "    csvName : TYPE, optonal.\n",
    "        DESCRIPTION. The default is ''. This will be the name of the csv file.\n",
    "        You can also add this to the end of :saveTo: instead.\n",
    "\n",
    "    csvIndex : TYPE, optional\n",
    "        DESCRIPTION. The default is False. Change to True if you wish to add\n",
    "        an index to your final csv file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    dictionary = {\"Files\" : [],\n",
    "                  \"Shortnames\" : [],\n",
    "                  \"Dates\" : [],\n",
    "                  \"RA\" : [],\n",
    "                  \"DEC\" : [],\n",
    "                  \"model\" : [],\n",
    "                  \"instrument\" : [],\n",
    "                  \"teff\" : [],\n",
    "                  \"logg\" : [],\n",
    "                  \"z\" : [],\n",
    "                  \"enrich\" : [],\n",
    "                  \"stat\" : [],\n",
    "                  \"scale\" : [],\n",
    "                  \"radius\" : []}\n",
    "\n",
    "\n",
    "    modelFitKeyList = [\"model\",\n",
    "                  \"instrument\",\n",
    "                  \"teff\",\n",
    "                  \"logg\",\n",
    "                  \"z\",\n",
    "                  \"enrich\",\n",
    "                  \"stat\",\n",
    "                  \"scale\",\n",
    "                  \"radius\"]\n",
    "\n",
    "    if isinstance(Files, list) == False:\n",
    "        Files = [Files]\n",
    "\n",
    "    for file in Files:\n",
    "        givePercentage(file, Files)\n",
    "        name = file[11:-12]\n",
    "        date = file[21:-5]\n",
    "        p = Classify(path=path, file=file, name=name)\n",
    "        s = Source(path_name=path+file)\n",
    "        ### Part 1\n",
    "        try:\n",
    "            for i in range(len(modelList)):\n",
    "                dictionary[\"Files\"].append(file)\n",
    "                dictionary[\"Shortnames\"].append(\"J\" + name)\n",
    "                dictionary[\"Dates\"].append(date)\n",
    "                dictionary[\"RA\"].append(s.RA)\n",
    "                dictionary[\"DEC\"].append(s.DEC)\n",
    "\n",
    "        except:\n",
    "            print(\"Part 1 failed\")\n",
    "\n",
    "        ### Part 2\n",
    "        try:\n",
    "            for model in modelList:\n",
    "                givePercentage(model, modelList)\n",
    "                modelFit = p.modelFitGrid(model=model)\n",
    "                keys = modelFitKeyList\n",
    "                for key in keys:\n",
    "                    if key in list(modelFit.keys()):\n",
    "                        if key == \"radius\":\n",
    "                            dictionary[key].append(modelFit[key].value)\n",
    "                        else:\n",
    "                            dictionary[key].append(modelFit[key])\n",
    "\n",
    "                    if key not in list(modelFit.keys()):\n",
    "                        dictionary[key].append(np.nan)\n",
    "        except:\n",
    "            print(\"Part 2 failed\")\n",
    "\n",
    "    csvFileName = saveTo + csvName\n",
    "    df = pd.DataFrame(data = dictionary, columns = list(dictionary.keys()))\n",
    "    df.to_csv(csvFileName, index=csvIndex, header=True)\n",
    "    print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
